<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>diary - 7&nbsp; week8</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./intro.html" rel="next">
<link href="./week7.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./week8.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">week8</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">diary</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">An Introduction to Remote Sensing</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">week2-NPP-VIIRS</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">week3-Remote sensing data pre-processing</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">week4-Policy applications</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">week6-GEE</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">week7-Classification</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week8.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">week8</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#summary" id="toc-summary" class="nav-link active" data-scroll-target="#summary"><span class="header-section-number">7.1</span> Summary</a>
  <ul class="collapse">
  <li><a href="#advanced-classification-methods" id="toc-advanced-classification-methods" class="nav-link" data-scroll-target="#advanced-classification-methods"><span class="header-section-number">7.1.1</span> Advanced Classification Methods</a></li>
  </ul></li>
  <li><a href="#applications" id="toc-applications" class="nav-link" data-scroll-target="#applications"><span class="header-section-number">7.2</span> Applications</a></li>
  <li><a href="#reflection" id="toc-reflection" class="nav-link" data-scroll-target="#reflection"><span class="header-section-number">7.3</span> Reflection</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">7.4</span> References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">week8</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="summary" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="summary"><span class="header-section-number">7.1</span> Summary</h2>
<section id="advanced-classification-methods" class="level3" data-number="7.1.1">
<h3 data-number="7.1.1" class="anchored" data-anchor-id="advanced-classification-methods"><span class="header-section-number">7.1.1</span> Advanced Classification Methods</h3>
<p>We have continued to learn about land cover classification methods and also learnt to cope with different data, compared to what we learnt last week, this week is mainly about how to deal with different objects.</p>
<ol type="1">
<li>Object-Based Image Analysis (OBIA)</li>
</ol>
<p>OBIA is based on the geometrical and spectral properties of objects in an image for analysis and classification.</p>
<p>The main principle of the method is related to hyperpixels. It aggregates neighbouring image elements with similar properties into hyperpixels, which are used to represent the actual objects on the ground. The hyperpixels are in turn generated by the Simple Linear Iterative Clustering algorithm. This algorithm calculates spatial distances and colour differences among regular points on the image, which can determine which image elements should be combined into a single hyperpixel, typically after 4-10 iterations, to better reflect the shape and size of the target object.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/8.1.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">After pre-processing and feature extraction with spectral gradient and K-means clustering, simple non-iterative clustering and calculation of NDVI, super-pixel segmentation, training of CART using training data, classification of multi-band images (I think further optimisation is needed for image segmentation of classification objects)</figcaption>
</figure>
</div>
<ul>
<li>Advantages:</li>
</ul>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 93%">
</colgroup>
<tbody>
<tr class="odd">
<td>1.</td>
<td>Can more accurately represent the actual objects on the ground such as buildings, more accurate classification results</td>
</tr>
<tr class="even">
<td>2.</td>
<td>Has a variety of classifiers and software packages that can use different algorithms to provide more complex analyses and functions, such as Supercells package can use any distance measure</td>
</tr>
</tbody>
</table>
<ul>
<li>Limitations:</li>
</ul>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 93%">
</colgroup>
<tbody>
<tr class="odd">
<td>1.</td>
<td>Does not take into account the connectivity between superpixels, which may lead to very small and difficult to interpret classification regions</td>
</tr>
<tr class="even">
<td>2.</td>
<td>using the Euclidean distance metric limits the suitable data types and classification needs.</td>
</tr>
<tr class="odd">
<td>3.</td>
<td>Performed in LAB colour space, which requires conversion of the raw data, affecting the accuracy of the classification.</td>
</tr>
</tbody>
</table>
<ol start="2" type="1">
<li>Subpixel analysis</li>
</ol>
<p>This method is mainly used when a single pixel contains multiple land cover types and is also called spectral mixture analysis (SMA). Rather than assigning an entire pixel to one dominant land cover class, it estimates the proportion of each land cover type in the pixel.</p>
<p>The basic principle is that the reflectance captured by a pixel is a combination of the reflectance of all land cover types (endmembers) within that pixel. By using the purely spectral characteristics of these endmembers, the analysis attempts to reverse derive the proportion of each endmembers contribution to the observed pixel value.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/8.2.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Using Dar-es-salaam as the study area, the sub-pixel analysis was completed by using Landsat 8 with dynamic end-element extraction, calculating the average spectral value of the delineated area, and calculating the percentage of each pixel in the image for each end-element type.</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/8.3.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">The subpixel images were enhanced and classified for each pixel with the largest percentage of land cover (e.g., 50% or more). Reducing the subpixel results to a single classification prepares the way for later use of traditional error matrix methods to assess classification accuracy.</figcaption>
</figure>
</div>
<ul>
<li>Advantages:</li>
</ul>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 93%">
</colgroup>
<tbody>
<tr class="odd">
<td>1.</td>
<td>Provides a more detailed understanding of land cover by disaggregating the components within a pixel, further effectively improving the resolution of land cover information compared to full pixel classification</td>
</tr>
<tr class="even">
<td>2.</td>
<td>better capture minor changes in the landscape as the land is monitored over time</td>
</tr>
</tbody>
</table>
<ul>
<li>Limitations:</li>
</ul>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 93%">
</colgroup>
<tbody>
<tr class="odd">
<td>1.</td>
<td>Computationally complex, the more end-elements considered the more computationally intensive</td>
</tr>
<tr class="even">
<td>2.</td>
<td>Accuracy depends on the purity of the end elements. Impure spectral features can lead to unreliable results</td>
</tr>
<tr class="odd">
<td>3.</td>
<td>Analyses are limited by spectral library data, so comprehensive spectral libraries are needed as much as possible</td>
</tr>
</tbody>
</table>
<ol start="3" type="1">
<li>Assessment of classification accuracy</li>
</ol>
<ul>
<li>Confusion Matrix</li>
</ul>
<p>Confusion matrices are often used when performing accuracy assessments, being able to compare the classification results with an independent dataset of real ground conditions, providing a detailed view of the classification performance including: true positives (TP), false positives (FP), true negatives (TN) and false negatives (FN). And the accuracy values can be obtained through the confusion matrix.</p>
<ul>
<li>Classification of accuracy values</li>
</ul>
<table class="table">
<caption>Table of accuracy value type</caption>
<colgroup>
<col style="width: 13%">
<col style="width: 86%">
</colgroup>
<thead>
<tr class="header">
<th>Accuracy value</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Producer’s accuracy</td>
<td>A measure of accuracy from the producer’s perspective. Indicates the ratio of pixels that are correctly classified to all relevant pixels in that category (i.e., the sum of true positives and false negatives)</td>
</tr>
<tr class="even">
<td>User accuracy</td>
<td>Measures the ratio of correctly classified pixels to all pixels classified as that category (i.e., the sum of true positives and false positives). User accuracy is concerned with whether a pixel classified as a category actually belongs to that category</td>
</tr>
<tr class="odd">
<td>Overall Accuracy</td>
<td>Indicates the proportion of correctly classified pixels across all categories and reflects the overall performance of the classification model</td>
</tr>
</tbody>
</table>
<p>In fact, application scenarios as well as requirements have to be considered when assessing the accuracy of classification models. For example, for land cover change detection, high overall accuracy may be most important. And for environmental monitoring, user accuracy may be more critical.</p>
<p>Generally the Kappa coefficient can be used to assess the difference between classification accuracy and random classification accuracy, with higher values indicating better classification accuracy and greater likelihood of exceeding random classification. However, it has also been argued (<a href="https://www.sciencedirect.com/science/article/pii/S0034425719306509">Foody 2020</a>) that the Kappa coefficient does not directly reflect accuracy; it is simply a measure of classification consistency beyond the random level, and can indicate either consistency obtained by chance alone or almost perfect consistency, and the interpretation of its true significance is often ambiguous.</p>
<ul>
<li>Validation data with cross-validation methods</li>
</ul>
<p>Leave-One-Out Cross-Validation</p>
<p>The number of folds is equal to the number of data points, and each iteration uses all but one data point for training and the missed points for testing. While maximising the amount of data used for training, the number of iterations is high and not practical for large datasets.</p>
<p>Spatial cross-validation</p>
<p>Due to the first law of geography (observations close to each other are more likely to be similar), the method spatially partitions the data so that the training and validation sets are not geographically intersected to avoid due to spatial autocorrelation.</p>
<table class="table">
<caption>Characteristics of Spatial cross-validation</caption>
<colgroup>
<col style="width: 22%">
<col style="width: 77%">
</colgroup>
<thead>
<tr class="header">
<th>Characteristic</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1. Advantage</td>
<td>in reducing the risk of overfitting the model to spatially similar data</td>
</tr>
<tr class="even">
<td>2. Requirement</td>
<td>Sufficient data distribution is needed to create meaningful spatial partitions</td>
</tr>
<tr class="odd">
<td>3. Optimisation</td>
<td>the hyperparameters of the SVM classifier need to be tuned to balance the model complexity and generalisation capabilities</td>
</tr>
<tr class="even">
<td>4. Multiple iterations</td>
<td>Multiple rounds of spatial partitioning and validation are required to ensure robustness</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="applications" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="applications"><span class="header-section-number">7.2</span> Applications</h2>
<p>In conjunction with this week’s classification method, I have taken a look at its position in the development of remote sensing applications.</p>
<p>Land use information has been extracted in different ways at different times in the development of remote sensing technology. In the early days, images captured by remote sensing sensors had larger pixels than ground features at low and medium resolution, so subpixel analysis was needed to respond to land class features(<a href="https://www.sciencedirect.com/science/article/pii/S0924271609000884">Blaschke 2010</a>). However, in the gradual increase of high-resolution imagery applications, the pixel-based analysis method is not able to respond to the spatial variations of land cover, so object-based image analysis becomes an effective method in high spatial resolution imagery applications. Due to its spectral, spatial, textural, and topological characteristics, and its ability to respond to geographic information, there has been a gradual increase in the number of studies and techniques related to geographic object-based image analysis (GEOBIA) (<a href="https://www.cambridge.org/core/journals/polar-record/article/remote-sensing-digital-image-processing-in-remote-sensing-jp-muller-editor-1988-london-taylor-and-francis-275-p-illustrated-hard-cover-isbn-0850663148-3800-us8400/7CCF3D9EED97C78CE8C6AB431647C513">Rees 1989</a>).</p>
<p>Manne et al.&nbsp;(<a href="Object based Classification of Multispectral Remote Sensing Images for Forestry Applications">Suneetha et al.&nbsp;2020</a>) used object-based image analysis with three separate stages of segmentation, generation of training data and final classification to obtain the range of forestry based on remote sensing satellite images such as Deimos-2 and Cartosat-1. As learnt in the course. The measurement of the classification results was determined from four main aspects, namely, Producers Accuracy, Users Accuracy, Overall Accuracy and Kappa coefficient value. Although the accuracy value of the data in Cartosat-1 is low and the interpretation of the Kappa coefficient is debatable. However, it can show the usefulness of the method for multispectral image classification and can support the real needs such as ecological monitoring.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Classified map of Deimos-2 using OBIA technique with radius 5.png" class="img-fluid figure-img" width="532"></p>
<figcaption class="figure-caption">Classified map of Deimos-2 using OBIA technique with radius 5 in (a) and 10 in (b) (<a href="https://dl.acm.org/doi/10.1145/3383812.3383824">Suneetha et al.&nbsp;2020</a>)</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Accuracy assessment of OBIA.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Accuracy assessment of OBIA: Deimos-2 (R 10) 150 samples (<a href="https://dl.acm.org/doi/10.1145/3383812.3383824">Suneetha et al.&nbsp;2020</a>)</figcaption>
</figure>
</div>
<p>Hossain et al.&nbsp;(<a href="https://www.sciencedirect.com/science/article/pii/S0924271619300425">Hossain &amp; Chen 2019</a>) summarised the research trends in image analysis based on geographic objects, and were able to find that the ability to match objects segmented from images with meaningful geographic objects is the key challenge in this field, and we can intuitively see that the cases and tools for this classification technique are improving significantly, so I also believe that continuous improvement of image segmentation techniques is also the future direction of research.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/1-s2.0-S0924271619300425-gr1.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">The amount of GEOBIA literature and some associated triggers(<a href="https://www.sciencedirect.com/science/article/pii/S0924271619300425">Hossain &amp; Chen 2019</a>)</figcaption>
</figure>
</div>
</section>
<section id="reflection" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="reflection"><span class="header-section-number">7.3</span> Reflection</h2>
<p>After two weeks of learning about the classification process in remote sensing in detail, last week focused on the basic methods of classification such as CART, Random Forest and Support Vector Machines. This was mainly about classifying for single pixels, and this week further emphasised on classifying for super-pixel cases, and sub-pixel cases, as a step-by-step process. It had not occurred to me last week that there would also be classification for different objects, and this week’s classification study has inspired me. Indeed, in practical remote sensing applications, the needs are constantly increasing, so the classification methods are constantly improving. I think in the future, continue to improve the robustness of multispectral image segmentation algorithms, improve the edge, time and other feature sets, and improve the classification rules of decision trees(<a href="https://doi.org/10.1007/s11769-006-0282-0">Liu et al.&nbsp;2006</a>) will have continued research value in the field, and I also hope that more learning based on the object to complete the ecological monitoring aspects of the work, which is greatly beneficial to sustainable development and disaster monitoring.</p>
<p>Meanwhile after a few weeks of systematic learning, we had a general understanding of the process of processing remote sensing data once we got it, just like the process of classification, which is from class definition, preprocessing, training, pixel assignment, and then accuracy assessment, and in the practical exercises, we also used GEE to understand how most of them work, which helped us to understand what we had learnt in the class. I also learnt through searching for applications that despite the different objects being classified, the classification tool methods used (e.g.&nbsp;decision trees) are common, which more than anything else allowed me to tie the two weeks of classes together.</p>
<p>This week’s course also brought us a lot of dialectical thinking, through the study of accuracy verification I learnt that the starting point for thinking about a problem and evaluating the results is different for different objects (producers and users), and that we have different criteria for evaluating the results in different application scenarios. As in the example of kappa coefficients, their interpretative and imperative nature is not entirely certain, despite the fact that many scholars see them as agreed-upon steps. I think this is the idea that the instructor has been instilling in this course, to maintain <em>CRITICAL THINKING</em>, even in published articles.</p>
</section>
<section id="references" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="references"><span class="header-section-number">7.4</span> References</h2>
<p>Blaschke, T., 2010. Object based image analysis for remote sensing, <em>ISPRS Journal of Photogrammetry and Remote Sensing</em>, årg. 65, nr. 1, s. 2–16.<br>
</p>
<p>Foody, G.M., 2020. Explaining the unsuitability of the kappa coefficient in the assessment and comparison of the accuracy of thematic maps obtained by image classification, <em>Remote Sensing of Environment</em>, årg. 239, s. 111630.<br>
</p>
<p>Hossain, M.D.&nbsp;&amp; Chen, D., 2019. Segmentation for Object-Based Image Analysis (OBIA): A review of algorithms and challenges from remote sensing perspective, <em>ISPRS Journal of Photogrammetry and Remote Sensing</em>, årg. 150, s. 115–134.<br>
</p>
<p>Liu, Y. et al., 2006. Review of remotely sensed imagery classification patterns based on object-oriented image analysis, <em>Chinese Geographical Science</em>, årg. 16, nr. 3, s. 282–288.<br>
</p>
<p>Rees, G., 1989. Remote Sensing - Digital image processing in remote sensing., <em>Polar Record</em>, årg. 25, nr. 152, s. 67–67.<br>
</p>
<p>Suneetha, M. et al., 2020. <em>Object based Classification of Multispectral Remote Sensing Images for Forestry Applications</em> [Online]. New York, NY, USA: Association for Computing Machinery.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./week7.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">week7-Classification</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./intro.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Introduction</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>