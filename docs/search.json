[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "diary",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "week2.html#xaringan-presentation---ikonos-2",
    "href": "week2.html#xaringan-presentation---ikonos-2",
    "title": "2  week2",
    "section": "2.1 Xaringan Presentation - IKONOS-2",
    "text": "2.1 Xaringan Presentation - IKONOS-2\nThe content for week 2 is a presentation in Xaringan on the Ikonos-2 satellite. The presentation is below, and the summary, application and reflection are all included in the slides."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "3  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  week1",
    "section": "",
    "text": "1. Summary"
  },
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "1  An Introduction to Remote Sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\n\n1.1.1 Active vs Passive\nThe content of this chapter focuses on the working principles of active and passive remote sensing.\n\nTable 1. Comparison of the characteristics of active and passive remote sensing\n\n\n\n\n\n\n\n\nPassive\nActive\n\n\n\n\nEnergy use\nUse existing energy, do not emit anything\nHas an illuminated energy source\n\n\nDetection method\nDetects energy reflected from the sun, receives electromagnetic radiation emitted or reflected by the observed object itself\nActively emits electronically mediated waves and then waits for reception\n\n\nExamples\nHuman eyes, cameras, satellite sensors\nRadar, x-ray, lidar\n\n\n\nBased on respective characteristics, we are able to summarize the benefits and limitations of each of the two types of remote sensing.\n\nTable 2. Comparison of advantages and disadvantages of active remote sensing\n\n\n\n\n\n\nBenefits\nLimitations\n\n\n\n\n1. Unaffected by sunlight and able to observe both day and night.\n1. Reflected signals may be interfered with by other objects in nature or by electromagnetic noise.\n\n\n2. More sensors, need to adjust the wavelength of emission, able to measure height, terrain, wind, etc.\n2. Requires its own energy to transmit signals, limiting its use in drones or satellite platforms.\n\n\n3. Have penetration capabilities such as SAR to penetrate clouds and vegetation to obtain information on surface or subsurface structures.\n\n\n\n\n\nTable 3. Comparison of advantages and disadvantages of passive remote sensing\n\n\n\n\n\n\nBenefits\nLimitations\n\n\n\n\n1. Low energy consumption, requiring less energy, long mission times, low manufacturing and operating costs, and can be easily deployed and utilized on a large scale.\n1. Dependent on lighting conditions, performance is limited under poor ambient light conditions. The spectral range is also dependent on the spectral properties of the natural light source, resulting in limitations in observing certain specific wavelength bands.\n\n\n2. Capable of capturing a wide range of spectral information using sunlight, it is suitable for multiple scenarios\n2. The received irradiance is mainly off-water irradiance, which can only be observed in specific atmospheric windows, and signals in other bands will be absorbed and masked. Susceptible to atmospheric components.\n\n\n\nFuture Development Trends\n\nMiniaturization and refinement of equipment: I believe that remote sensing equipment needs to address its own limitations, for example, active remote sensing equipment needs to become smaller and lighter in order to be deployed on a wide range of platforms. Similarly, passive remote sensing should be widely used in low-cost, high-frequency Earth observation missions.\nContinued integration with machine learning: Advanced algorithms are indispensable for both processing and analyzing remote sensing data. Deep learning models such as convolutional neural networks (CNN) are now widely used to automatically identify and classify features from active remote sensing data.\n\n\n\n\nActive and passive microwave satellites are widely used on global and regional scales to invert surface soil moisture changes (Mousa et al. 2020)\n\n\nIn the future, there is a need to develop more optimized machine learning models that combine active and passive remote sensing data to be able to process and interpret remote sensing data more accurately.\n\n\n1.1.2 Consider how electromagnetic waves interact\nInteractions at the Earth’s surface\n\nAbsorption by surfaces: Surface materials absorb electromagnetic waves of certain wavelengths. For example, vegetation strongly absorbs infrared light but reflects near-infrared light. By observing the absorption properties at specific wavelengths, the nature and condition of the surface material can be inferred.\nTransmission through the surface: When electromagnetic waves such as sunlight reach the Earth’s surface, they are reflected back into space. Different surface types, such as water bodies, vegetation, and urban buildings, have different reflectance properties that can be quantified by a bidirectional reflectance distribution function (BRDF). By analyzing the reflectance at different wavelengths, surface materials can be identified and classified.\n\nAtmospheric interactions\n1.Scattering: as electromagnetic waves pass through the atmosphere, they scatter with gas molecules, water droplets, and other particles in the atmosphere. For example, Rayleigh scattering gives the sky a blue color. This scattering changes the direction and intensity of electromagnetic waves and affects the quality of remotely sensed data.\n2.Countermeasure: Removal of the sensor’s exposure to atmospheric scattering using synthetic aperture radar (SAR) and through atmospheric correction\n\n\n\nHelping to Understand the Principles of Observations Using the Electromagnetic Spectrum (NASA Science)\n\n\n\n\n1.1.3 Resolution\nWe explored 4 resolutions for remotely sensed data\n\nTable 4. Distinction between four remote sensing resolutions\n\n\n\n\n\n\nResolution type\nCharacteristic explanation\n\n\n\n\nSpectral\nObtaining values for each wavelength (or band of multiple wavelengths) in the electromagnetic spectrum to create spectral features, which may be discrete (multispectral) or continuous (hyperspectral)\n\n\nSpatial\nIn most cases, remotely sensed data are rasters. Spatial resolution refers to the size of the raster image element\n\n\nTemporal\nTemporal resolution relates to how frequently surface data are updated, the time interval between revisits to the same location by a remote sensing sensor\n\n\nRadiometric\nThe ability of a sensor to recognize and display small differences in energy. For example, an 8-bit image can represent 256 different gray levels (or colors). In an 8-bit image, the transition from dark to light is smoother and more subtle changes can be captured\n\n\n\nNotably, sensors that are able to resolve narrower band widths, have more bands, cover a wider spectral range, and have a finer band layout for key spectral features are considered to have higher spectral resolution.\nOften temporal and spatial resolution together influence the suitability of remotely sensed data for a particular application, e.g. a sensor with a low spatial resolution but a high temporal resolution (MODIS) is better suited for tracking and monitoring environmental change or agricultural development, etc.\n\n\n\nDifferent spatial resolutions are available for specific observation or research needs (NASA Earthdata)"
  },
  {
    "objectID": "week1.html#education",
    "href": "week1.html#education",
    "title": "1  week1",
    "section": "1.2 Education",
    "text": "1.2 Education\nUniversity of California, San Diego | San Diego, CA PhD in Mathematics | Sept 2011 - June 2015\nMacalester College | St. Paul MA B.A in Economics | Sept 2007 - June 2011"
  },
  {
    "objectID": "week1.html#experience",
    "href": "week1.html#experience",
    "title": "1  week1",
    "section": "1.3 Experience",
    "text": "1.3 Experience\nWengo Analytics | Head Data Scientist | April 2018 - present\nGeoScynce | Chief Analyst | Spet 2012 - April 2018"
  },
  {
    "objectID": "week1.html#applications",
    "href": "week1.html#applications",
    "title": "1  An Introduction to Remote Sensing",
    "section": "1.2 Applications",
    "text": "1.2 Applications\n\n1.2.1 Remote sensing applications are characterised by inter-temporal and spatial features\nFirstly, remote sensing technology can be applied to Earth issues at different spatial scales, from a small pixel to a scene, from a region to a country, and has become the main way of global Earth observation.\n\n\n\nThe use of the Sunglint phenomenon (sunlight reflected off the surface of the water to make the water appear grey, silver or white) can help to monitor the pattern of currents on the surface of the ocean around the Canary Islands (LANCE/EOSDIS MODIS Rapid Response Team).\n\n\nIn addition, remote sensing has the technology to analyse across time, and dynamic monitoring of indicators such as temperature, precipitation, biomass and other indicators in nature or targets such as lakes, rivers and roads can be accomplished in instantaneous or long time series, which can be determined by the temporal resolution of different remote sensing.\n\n\n1.2.2 Remote sensing technology has been used in all aspects of natural resources and human activities.\nIn the field of environment remote sensing can perform a series of environmental monitoring including soil erosion, water pollution, urban heat island, etc. Xu et al. (Xu & Chen 2004) 6th band acquisition of thermal remote sensing data from Landsat TM/ETM+ imagery observed the changes of urban heat island phenomenon in Xiamen, China within 11 years. In resource management remote sensing can be engaged in geological structure identification, glacier, coastline and island change monitoring, etc. Ke et al. (Ke et al. 2016) demonstrated different types of glaciers in three typical glacier-intensive subregions of the plateau based on elevation data from ICESat and Landsat images. In disaster prevention and mitigation, the role of remote sensing in monitoring extreme weather such as El Niño is irreplaceable.Hoque et al. (Hoque et al. 2017) suggest that object-based image analysis using optical images with a resolution of up to 30 metres can provide better impact assessment and recovery from tropical cyclones. I believe that the role of remote sensing in global environmental monitoring and response to climate change will be further enhanced as the impacts of global environment and climate change become more significant.\n\n\n\nRecognition applications of remote sensing also need to be continually refined, as reflected in this Himalayan MODIS image of 1 November 2013, which reflects the fact that it is not always possible to distinguish between haze, fog, clouds and snow in the visual interpretation of satellite imagery (How to Interpret a Satellite Image: Five Tips and Strategies)"
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1  An Introduction to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nI had been exposed to the course Introduction to Remote Sensing in my undergraduate studies, but had less practical use of remote sensing. Having used a combination of NPP-VIIRS nighttime lighting data and impervious surface data to define the extent of urban built-up areas in my undergraduate projects, I have developed a unique interest in the process of using remote sensing imagery to portray human activity. For this course, I think it can teach me well about how remote sensing technology can be used to solve practical environmental problems in the context of sustainable development. This course has taught me about downloading and using different sensors and has given us the opportunity to utilise platforms such as SNAP to manipulate Sentinel imagery, giving us very much hands-on opportunities.\nIn my future studies, I hope to get more exposure to different remote sensing sensors and methods of processing remote sensing data, applying them to practical research and integrating them with existing environmental policies, such as helping to meet carbon neutral targets, is something I hope to do and will make this course more meaningful."
  },
  {
    "objectID": "week1.html#references",
    "href": "week1.html#references",
    "title": "1  An Introduction to Remote Sensing",
    "section": "1.4 References",
    "text": "1.4 References\nHoque, M.A.-A. et al., 2017. Tropical cyclone disaster management using remote sensing and spatial analysis: A review, International Journal of Disaster Risk Reduction. Amsterdam: Elsevier, årg. 22, s. 345–354.\nKe, L. et al., 2016. Remote sensing of glacier distribution and change over the Qinghai-Tibet Plateau [Online]. New York: IEEE.\nhttps://www.webofscience.com/wos/woscc/full-record/WOS:000389576700094\nXu, H.Q. & Chen, B.Q., 2004. Remote sensing of the urban heat island and its changes in Xiamen City of SE China, International journal of disaster risk reduction, årg. 16, nr. 2, s. 276–281."
  },
  {
    "objectID": "week2.html#xaringan-presentation---npp-viirs",
    "href": "week2.html#xaringan-presentation---npp-viirs",
    "title": "2  week2-NPP-VIIRS",
    "section": "2.1 Xaringan Presentation - NPP-VIIRS",
    "text": "2.1 Xaringan Presentation - NPP-VIIRS\nThe content for week 2 is a presentation in Xaringan on the Visible Infrared Imaging Radiometer Suite satellite. The presentation is below, and the summary, application and reflection are all included in the slides."
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "3  week3-Remote sensing data pre-processing",
    "section": "3.1 Summary",
    "text": "3.1 Summary\n\n3.1.1 Image correction\nThe week began with a study of the different correction methods and their principles, which I will summarise in terms of their characteristics.\n\nGeometric correction and its Response Scenario: When collecting remote sensing data, there are image distortions due to viewing angle, terrain, wind, earth rotation, etc.\n\n\nMain steps of geometric correction\n\n\n\n\n\n\n\nStep\nName\nDefinition\n\n\n\n\n1\nIdentify GCPs and transform coordinates\nIdentify ground control points (GCPs) in the image using data such as local maps. Derive geometric transformation coefficients in terms of the coordinates of the GCPs and use polynomial functions to map the distorted image coordinates to the correct geographic coordinates.\n\n\n2\nRegression analysis and optimisation of the fit\nTechniques such as linear regression are used to correlate distorted x or y coordinates with undistorted coordinates from the GCP. The root mean square error (RMSE) is calculated to measure the accuracy of the correction. Adjustments are made to minimise the RMSE.\n\n\n3\nResampling\nafter computing the transform coefficients, the image is resampled to match the corrected coordinates. Resampling methods include nearest neighbour, linear, cubic and cubic spline.\n\n\n\n\nGeometric correction limitations\n\n\n\n\n\n\n\nNo.\nlimitations\nDefinition\n\n\n\n\n1\nDependence on high-quality ground control points\nIf these points are not of high quality (e.g., inaccurate positioning), this may lead to inaccurate results in the calibration process.\n\n\n2\nLoss of data quality due to resampling\nsome data quality may be lost due to interpolation during the resampling process. For example, nearest neighbour interpolation may lead to pixelation effects, and linear and cubic interpolation may introduce data smoothing.\n\n\n3\nAffected by environmental conditions\nIn complex or rapidly changing terrain (e.g., mountains or canyons), it may be difficult to obtain accurate geometric corrections, even when using GCPs. If the environment is rapidly changing, the final image may not accurately reflect current conditions, even with geometric correction.\n\n\n4\nHigher cost\nA large amount of manual input is required in selecting and validating GCPs. Being a computationally intensive process increases the overall resource and time requirements of the project.\n\n\n\n\nAtmospheric correction and its application scenarios: Used to eliminate the effect of atmospheric gases and particles on light captured by remote sensing instruments, as the atmosphere can scatter and absorb light and thus change the true reflectance value of the Earth’s surface as seen by the sensor.\n\n\nTypes of atmospheric corrections and characteristics\n\n\n\n\n\n\n\nType\nBenefit\nlimitation\n\n\n\n\nRelative correction\n1. This can be done using the image data itself without additional atmospheric information.\n1. May not be able to fully correct for all atmospheric effects when conditions vary greatly between images.\n2. Less suitable for quantitative analyses requiring precise reflectance values.\n\n\nAbsolute correction\n1. Provide more accurate corrections by using physical models of atmospheric properties\n1. Detailed atmospheric data, such as local atmospheric visibility, are required\n2. Models must be carefully selected and calibrated to the specific conditions of the image.\n\n\nExperience line correction\n1. Provide more targeted calibration for the time and conditions of image acquisition.\n2. correctly collect in-situ measurements to ensure calibration accuracy.\n1. Demanding conditions: In situ measurements must be made simultaneously with the satellite overpass to ensure that atmospheric conditions are matched. The selected ground targets must be well distributed throughout the image and cover the range of reflectivity values present in the scene.\n\n\n\n\n\n\nDigitalGlobe Atmospheric Compensation (DG AComp) original image (left) and atmospherically corrected image (right) (Lee & Yum 2019)\n\n\n\nOrthometric and Radiometric correction\n\n\nSummary of the characteristics of orthographic and radiometric calibration\n\n\n\n\n\n\n\nCorrection\nBenefit\nlimitation\n\n\n\n\nOrthorectification\n1. The spatial accuracy of the imagery is improved to measure true distances, angles and areas.\n2. Can be seamlessly integrated into GIS, and deformed images become easier to interpret in tasks such as element extraction and land cover classification.\n1. High calibration requirements If the DEM or sensor geometry is inaccurate, errors are introduced rather than corrected.\n\n\nRadiation correction\n1. In cases where the signal received by the sensor is affected by atmospheric conditions, angles, etc., radiometric correction reduces the impact on the quality of the data for comparison with different sensors at different times.\n1. The conditions are demanding; solar altitude angle affects the intensity of the radiation, and remotely sensed images are usually acquired at times when the solar altitude angle is relatively high and atmospheric conditions are stable. Properly performed radiometric corrections also require adequate sensor calibration information, such as gain and offset.\n\n\n\n\n\n3.1.2 Data joining and enhancement\n\nData joining\n\n\nThe counterpart to GIS merging in remote sensing is called tessellation. Feathering using a base image and other images is used to reduce the effect of seam lines.\nFeathering is different in different cases: usually based on representative samples and histogram matching algorithms it is possible to obtain similar luminance of two images for feathering\nComparison between multiple images on the same area or when processing images at different times\nUse normalisation and normalisation of Surface Reflectance (SR)\nUse Permanent Invariant Features (PIFs, Permanent Invariant Features) or other surface features that do not change over time to calibrate differences between multiple images.\n\n\nData enhancement\n\nIn order to improve the visual appearance or outcome, images can have different enhancements applied to them：\nSensors have a low band range in most of the images to avoid saturation, so methods like Minimum - Maximum, Percentage Linear and Standard Deviation, Piecewise Linear Contrast Stretch are used to add contrast.\nThere are also different ways to improve the image such as Ratio, Filtering, Principal Component Analysis, spatial variation of grey values, Data Fusion.\n\n\n\nAnalysis of texture features in a set of bands of LANDSAT in New Delhi region using Gray-Level Co-Occurrence Matrix (GLCM) texture analysis\n\n\n\n\n\nInfrared image enhancement process including decomposition, correlation measurements, reflectance component enhancement, illumination component enhancement and image reconstruction (Chen et al. 2020)"
  },
  {
    "objectID": "week3.html#applications",
    "href": "week3.html#applications",
    "title": "3  week3-Remote sensing data pre-processing",
    "section": "3.2 Applications",
    "text": "3.2 Applications\nSince remote sensing products are often already calibrated during the application phase, this time I focused on investigating the issue of image enhancement applications in the classroom.\n\nHow image enhancement methods can help the urban environment?\n\nThe computations such as image connectivity and enhancement learnt this week can be useful in real-world studies of urban environments. For example, in applications where edge enhancement of remotely sensed images is used to extract building footprints for monitoring natural disasters and urban development. The U-Net CNN architecture is one of the most basic networks in semantic segmentation, but such networks are not deep enough to detect detailed edge features.\nHoin Jung et al.(Jung, Choi & Kang 2022) used the edge features obtained by overall nested edge detection as inputs to their boundary enhancement module, where the two subunits of the module, detection boundary and segmentation mask, share information by combining probability graphs to represent the likelihood of the target object for boundary enhancement purposes. Compared with other semantic segmentation methods, the extracted architectural results of the proposed method in this study can have clear and subtle boundaries. In addition to extracting building information, the use of edge enhancement can also be used to obtain features of other features, such as the representation and extraction of spectral features of water bodies (Zhang & Lun 2023), which can help monitor the urban water environment.\n\nDoes increasing the complexity of the images (or creating new datasets) help us achieve our goals?\n\nContrast enhancement and filtering mainly improve or modify the visual quality or specific features of existing imagery, PCA and texture analysis may lead to the creation of new datasets and an increase in complexity.\nFor example, texture is defined by calculating a statistical measure of pixel values within a local area of the image, thus increasing the image dataset for texture measures. Dekker et al. (Dekker 2001)investigated the map updating capabilities of ERS SAR imagery in urban areas using texture measures and found mean intensity, variance, skewness, weighted rank fill rate, semi-variance function (or wavelet energy measure), and gap metrics several texture measures are capable of providing the best land cover separability for the Rotterdam area. Overall, enhancement techniques can increase the information content of the images in different ways, to some extent placing new demands on the analysis and interpretation of the data, but also accomplishing the appropriate goals for the research questions."
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  week3-Remote sensing data pre-processing",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nHonestly speaking, due to the previous exposure to corrected remote sensing products, this is the first time to learn the principles of remote sensing correction systematically.\nAs a matter of fact, correction procedures such as atmospheric correction and terrain correction are crucial for obtaining true information about the ground surface, just like in climate change research, failure to correctly correct for cloud cover or atmospheric effects may lead to misinterpretation of surface temperature and vegetation status. I believe that accurate image correction also ensures that decision makers can make more effective judgements in areas such as environmental monitoring, urban planning, and agricultural management.\nFor example, in the field of public safety, corrected images can be used in disaster response and emergency relief (Li et al. 2016) for real-time disaster monitoring. I believe that in the future, we can continue to extend image correction skills to different remote sensing platforms, such as UAVs or near-Earth observation, and thus improve the real-time and accuracy of disaster monitoring, which is very much in demand.\nAs mentioned in the application case, enhancement techniques such as PCA or filtering can be used to extract specific environmental features, which is very important in applied research in geological exploration, biodiversity. I also believe that integrating datasets of different formats, resolutions, and times is very necessary in practical research, because our research often requires the integration of a collection of remote sensing data from multiple sources as well as long time series in order to make the research more meaningful. Therefore, I found the data preprocessing and quality control methods learned in this literature to be very beneficial. In future research, I believe that integration with datasets from other disciplines (e.g. socio-economics, ecology) is necessary, which is the key to applying remote sensing to a wider range of real-world problems, and I have learnt that methods of augmenting datasets are constantly being updated, and I hope that I will be able to learn more advanced algorithms and models to deal with more complex datasets in the future, such as the use of machine learning techniques to automatically identify and classify surface features."
  },
  {
    "objectID": "week3.html#references",
    "href": "week3.html#references",
    "title": "3  week3-Remote sensing data pre-processing",
    "section": "3.4 References",
    "text": "3.4 References\nChen, J. et al., 2020. A Novel Infrared Image Enhancement Based on Correlation Measurement of Visible Image for Urban Traffic Surveillance Systems, Journal of Intelligent Transportation Systems. Taylor & Francis, årg. 24, nr. 3, s. 290–303.\n\nDekker, R.J., 2001. Texture analysis of urban areas in ERS SAR imagery for map updating [Online]. New York: IEEE.\n\nJung, H., Choi, H.-S. & Kang, M., 2022. Boundary Enhancement Semantic Segmentation for Building Extraction From Remote Sensed Image, IEEE Transactions on Geoscience and Remote Sensing, årg. 60, s. 1–12.\n\nLee, K.-H. & Yum, J.-M., 2019. A Review on Atmospheric Correction Technique Using Satellite Remote Sensing, Korean Journal of Remote Sensing. The Korean Society of Remote Sensing, årg. 35, nr. 6_1, s. 1011–1030.\n\nLi, Y. et al., 2016. Geometric correction algorithm of UAV remote sensing image for the emergency disaster [Online].\n\nZhang, Y. & Lun, H., 2023. Remote Sensing and Image Processing Techniques for Water Environment Monitoring: A Case Study of the Beijing-Tianjin-Hebei Region, TRAITEMENT DU SIGNAL. Edmonton: Int Information & Engineering Technology Assoc, årg. 40, nr. 4, s. 1771–1779."
  }
]